import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras
from PIL import Image, ImageFont, ImageDraw  # Pillow 임포트

# 모델 및 라벨 파일 경로
MODEL_PATH = "D:/herb_test/converted_savedmodel/model.savedmodel"  # 디렉터리 경로
LABELS_PATH = "D:/herb_test/converted_savedmodel/labels.txt"

# 모델과 레이블 불러오기
model = keras.layers.TFSMLayer(MODEL_PATH, call_endpoint="serving_default")  # TFSMLayer로 모델 불러오기
with open(LABELS_PATH, "r", encoding="utf-8") as f:  # UTF-8로 파일 읽기
    labels = [line.strip() for line in f.readlines()]

# 웹캠 피드 초기화
cap = cv2.VideoCapture(0)

# 한글 폰트 경로 설정 (예: 맑은 고딕 폰트)
font_path = "C:/Windows/Fonts/malgun.ttf"  # Windows 기본 한글 폰트로 설정
font = ImageFont.truetype(font_path, 24)


def predict(frame):
    # 프레임을 모델 입력에 맞게 변환
    img = cv2.resize(frame, (224, 224))  # Teachable Machine 기본 이미지 크기
    img = np.expand_dims(img, axis=0)  # 배치 차원 추가
    img = img.astype('float32') / 255.0  # 정규화

    # 예측 수행
    predictions = model(img)  # TFSMLayer를 호출하여 예측 수행
    pred_array = predictions['sequential_3'].numpy()  # 'sequential_3'에서 예측 배열 추출

    predicted_label = labels[np.argmax(pred_array)]
    confidence = np.max(pred_array)

    return predicted_label, confidence

def draw_text_with_pil(image, text, position, font, color=(255, 255, 255)):
    # OpenCV 이미지 -> Pillow 이미지로 변환
    img_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    draw.text(position, text, font=font, fill=color)
    # Pillow 이미지 -> OpenCV 이미지로 변환하여 반환
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

while True:
    # 카메라에서 프레임 읽기
    ret, frame = cap.read()
    if not ret:
        break

    # 예측 및 결과 표시
    label, confidence = predict(frame)
    text = f"{label} ({confidence * 100:.2f}%)"
    frame = draw_text_with_pil(frame, text, (10, 30), font)  # Pillow로 텍스트 그리기

    cv2.imshow("Plant Condition Recognition", frame)

    # 'q' 키로 종료
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()
